{"meta":{"title":"CarlSack Blog","subtitle":"","description":"CarlSack Blog","author":"CarlSack","url":"https://carlsack.github.io","root":"/"},"pages":[{"title":"所有标签","date":"2024-01-31T07:10:15.914Z","updated":"2023-08-03T16:33:49.000Z","comments":true,"path":"tags/index.html","permalink":"https://carlsack.github.io/tags/index.html","excerpt":"","text":""},{"title":"所有分类","date":"2024-01-31T07:10:15.914Z","updated":"2023-08-03T16:35:05.000Z","comments":true,"path":"categories/index.html","permalink":"https://carlsack.github.io/categories/index.html","excerpt":"","text":""}],"posts":[{"title":"常用git命令清单","slug":"常用git命令清单","date":"2024-02-01T08:10:17.000Z","updated":"2024-02-01T08:12:05.858Z","comments":true,"path":"2024/02/01/常用git命令清单/","permalink":"https://carlsack.github.io/2024/02/01/%E5%B8%B8%E7%94%A8git%E5%91%BD%E4%BB%A4%E6%B8%85%E5%8D%95/","excerpt":"","text":"常用Git命令清单 一般来说，日常使用只要记住下图6个命令，就可以了。但是熟练使用，恐怕要记住60～100个命令。 名次解释 几个专用名词的译名如下: Workspace：工作区 Index &#x2F; Stage：暂存区 Repository：仓库区（或本地仓库） Remote：远程仓库 一. 新建代码库12345678# 在当前目录新建一个Git代码库$ git init# 新建一个目录，将其初始化为Git代码库$ git init [project-name]# 下载一个项目和它的整个代码历史$ git clone [url] 二.配置Git的设置文件为.gitconfig，它可以在用户主目录下(全局配置)，也可以在项目目录下(项目配置) 1234567891011121314151617# 显示当前的Git配置$ git config --list# 编辑Git配置文件$ git config -e [--global]# 设置提交代码时的用户信息$ git config [--global] user.name &quot;[name]&quot;$ git config [--global] user.email &quot;[email address]&quot;# 颜色设置git config --global color.ui true # git status等命令自动着色git config --global color.status autogit config --global color.diff autogit config --global color.branch autogit config --global color.interactive autogit config --global --unset http.proxy # remove proxy configuration on git 三. 增加&#x2F;删除文件123456789101112131415161718192021# 添加指定文件到暂存区$ git add [file1] [file2] ...# 添加指定目录到暂存区，包括子目录$ git add [dir]# 添加当前目录的所有文件到暂存区$ git add .# 添加每个变化前，都会要求确认# 对于同一个文件的多处变化，可以实现分次提交$ git add -p# 删除工作区文件，并且将这次删除放入暂存区$ git rm [file1] [file2] ...# 停止追踪指定文件，但该文件会保留在工作区$ git rm --cached [file]# 改名文件，并且将这个改名放入暂存区$ git mv [file-original] [file-renamed] 四. 代码提交123456789101112131415161718192021# 提交暂存区到仓库区$ git commit -m [message]# 提交暂存区的指定文件到仓库区$ git commit [file1] [file2] ... -m [message]# 提交工作区自上次commit之后的变化，直接到仓库区$ git commit -a# 提交时显示所有diff信息$ git commit -v# 将add和commit合为一步$ git commit -am &#x27;message&#x27;# 使用一次新的commit，替代上一次提交# 如果代码没有任何新变化，则用来改写上一次commit的提交信息$ git commit --amend -m [message]# 重做上一次commit，并包括指定文件的新变化$ git commit --amend [file1] [file2] ... 五. 分支123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051# 列出所有本地分支$ git branch# 列出所有远程分支$ git branch -r# 列出所有本地分支和远程分支$ git branch -a# 新建一个分支，但依然停留在当前分支$ git branch [branch-name]# 新建一个分支，并切换到该分支$ git checkout -b [branch]# 新建一个分支，指向指定commit$ git branch [branch] [commit]# 新建一个分支，与指定的远程分支建立追踪关系$ git branch --track [branch] [remote-branch]# 切换到指定分支，并更新工作区$ git checkout [branch-name]# 切换到上一个分支$ git checkout -# 建立追踪关系，在现有分支与指定的远程分支之间$ git branch --set-upstream [branch] [remote-branch]# 合并指定分支到当前分支$ git merge [branch]# 选择一个commit，合并进当前分支$ git cherry-pick [commit]# 删除分支$ git branch -d [branch-name]# 删除远程分支$ git push origin --delete [branch-name]$ git branch -dr [remote/branch]# 检出版本v2.0$ git checkout v2.0# 从远程分支develop创建新本地分支devel并检出$ git checkout -b devel origin/develop# 检出head版本的README文件（可用于修改错误回退）git checkout -- README 六. 标签1234567891011121314151617181920212223242526# 列出所有tag$ git tag# 新建一个tag在当前commit$ git tag [tag]# 新建一个tag在指定commit$ git tag [tag] [commit]# 删除本地tag$ git tag -d [tag]# 删除远程tag$ git push origin :refs/tags/[tagName]# 查看tag信息$ git show [tag]# 提交指定tag$ git push [remote] [tag]# 提交所有tag$ git push [remote] --tags# 新建一个分支，指向某个tag$ git checkout -b [branch] [tag] 七. 查看信息123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960# 显示有变更的文件$ git status# 显示当前分支的版本历史$ git log# 显示commit历史，以及每次commit发生变更的文件$ git log --stat# 搜索提交历史，根据关键词$ git log -S [keyword]# 显示某个commit之后的所有变动，每个commit占据一行$ git log [tag] HEAD --pretty=format:%s# 显示某个commit之后的所有变动，其&quot;提交说明&quot;必须符合搜索条件$ git log [tag] HEAD --grep feature# 显示某个文件的版本历史，包括文件改名$ git log --follow [file]$ git whatchanged [file]# 显示指定文件相关的每一次diff$ git log -p [file]# 显示过去5次提交$ git log -5 --pretty --oneline# 显示所有提交过的用户，按提交次数排序$ git shortlog -sn# 显示指定文件是什么人在什么时间修改过$ git blame [file]# 显示暂存区和工作区的差异$ git diff# 显示暂存区和上一个commit的差异$ git diff --cached [file]# 显示工作区与当前分支最新commit之间的差异$ git diff HEAD# 显示两次提交之间的差异$ git diff [first-branch]...[second-branch]# 显示今天你写了多少行代码$ git diff --shortstat &quot;@&#123;0 day ago&#125;&quot;# 显示某次提交的元数据和内容变化$ git show [commit]# 显示某次提交发生变化的文件$ git show --name-only [commit]# 显示某次提交时，某个文件的内容$ git show [commit]:[filename]# 显示当前分支的最近几次提交$ git reflog 八. 远程同步1234567891011121314151617181920212223# 下载远程仓库的所有变动$ git fetch [remote]# 显示所有远程仓库$ git remote -v# 显示某个远程仓库的信息$ git remote show [remote]# 增加一个新的远程仓库，并命名$ git remote add [shortname] [url]# 取回远程仓库的变化，并与本地分支合并$ git pull [remote] [branch]# 上传本地指定分支到远程仓库$ git push [remote] [branch]# 强行推送当前分支到远程仓库，即使有冲突$ git push [remote] --force# 推送所有分支到远程仓库$ git push [remote] --all 九. 撤销12345678910111213141516171819202122232425262728293031# 恢复暂存区的指定文件到工作区$ git checkout [file]# 恢复某个commit的指定文件到暂存区和工作区$ git checkout [commit] [file]# 恢复暂存区的所有文件到工作区$ git checkout .# 重置暂存区的指定文件，与上一次commit保持一致，但工作区不变$ git reset [file]# 重置暂存区与工作区，与上一次commit保持一致$ git reset --hard# 重置当前分支的指针为指定commit，同时重置暂存区，但工作区不变$ git reset [commit]# 重置当前分支的HEAD为指定commit，同时重置暂存区和工作区，与指定commit一致$ git reset --hard [commit]# 重置当前HEAD为指定commit，但保持暂存区和工作区不变$ git reset --keep [commit]# 新建一个commit，用来撤销指定commit# 后者的所有变化都将被前者抵消，并且应用到当前分支$ git revert [commit]# 暂时将未提交的变化移除，稍后再移入$ git stash$ git stash pop 十. 其他12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485868788git init # 初始化本地git仓库（创建新仓库）git config --global user.name &quot;xxx&quot; # 配置用户名git config --global user.email &quot;xxx@xxx.com&quot; # 配置邮件git config --global color.ui true # git status等命令自动着色git config --global color.status autogit config --global color.diff autogit config --global color.branch autogit config --global color.interactive autogit config --global --unset http.proxy # remove proxy configuration on gitgit clone git+ssh://git@192.168.53.168/VT.git # clone远程仓库git status # 查看当前版本状态（是否修改）git add xyz # 添加xyz文件至indexgit add . # 增加当前子目录下所有更改过的文件至indexgit commit -m &#x27;xxx&#x27; # 提交git commit --amend -m &#x27;xxx&#x27; # 合并上一次提交（用于反复修改）git commit -am &#x27;xxx&#x27; # 将add和commit合为一步git rm xxx # 删除index中的文件git rm -r * # 递归删除git log # 显示提交日志git log -1 # 显示1行日志 -n为n行git log -5git log --stat # 显示提交日志及相关变动文件git log -p -mgit show dfb02e6e4f2f7b573337763e5c0013802e392818 # 显示某个提交的详细内容git show dfb02 # 可只用commitid的前几位git show HEAD # 显示HEAD提交日志git show HEAD^ # 显示HEAD的父（上一个版本）的提交日志 ^^为上两个版本 ^5为上5个版本git tag # 显示已存在的taggit tag -a v2.0 -m &#x27;xxx&#x27; # 增加v2.0的taggit show v2.0 # 显示v2.0的日志及详细内容git log v2.0 # 显示v2.0的日志git diff # 显示所有未添加至index的变更git diff --cached # 显示所有已添加index但还未commit的变更git diff HEAD^ # 比较与上一个版本的差异git diff HEAD -- ./lib # 比较与HEAD版本lib目录的差异git diff origin/master..master # 比较远程分支master上有本地分支master上没有的git diff origin/master..master --stat # 只显示差异的文件，不显示具体内容git remote add origin git+ssh://git@192.168.53.168/VT.git # 增加远程定义（用于push/pull/fetch）git branch # 显示本地分支git branch --contains 50089 # 显示包含提交50089的分支git branch -a # 显示所有分支git branch -r # 显示所有原创分支git branch --merged # 显示所有已合并到当前分支的分支git branch --no-merged # 显示所有未合并到当前分支的分支git branch -m master master_copy # 本地分支改名git checkout -b master_copy # 从当前分支创建新分支master_copy并检出git checkout -b master master_copy # 上面的完整版git checkout features/performance # 检出已存在的features/performance分支git checkout --track hotfixes/BJVEP933 # 检出远程分支hotfixes/BJVEP933并创建本地跟踪分支git checkout v2.0 # 检出版本v2.0git checkout -b devel origin/develop # 从远程分支develop创建新本地分支devel并检出git checkout -- README # 检出head版本的README文件（可用于修改错误回退）git merge origin/master # 合并远程master分支至当前分支git cherry-pick ff44785404a8e # 合并提交ff44785404a8e的修改git push origin master # 将当前分支push到远程master分支git push origin :hotfixes/BJVEP933 # 删除远程仓库的hotfixes/BJVEP933分支git push --tags # 把所有tag推送到远程仓库git fetch # 获取所有远程分支（不更新本地分支，另需merge）git fetch --prune # 获取所有原创分支并清除服务器上已删掉的分支git pull origin master # 获取远程分支master并merge到当前分支git mv README README2 # 重命名文件README为README2git reset --hard HEAD # 将当前版本重置为HEAD（通常用于merge失败回退）git rebasegit branch -d hotfixes/BJVEP933 # 删除分支hotfixes/BJVEP933（本分支修改已合并到其他分支）git branch -D hotfixes/BJVEP933 # 强制删除分支hotfixes/BJVEP933git ls-files # 列出git index包含的文件git show-branch # 图示当前分支历史git show-branch --all # 图示所有分支历史git whatchanged # 显示提交历史对应的文件修改git revert dfb02e6e4f2f7b573337763e5c0013802e392818 # 撤销提交dfb02e6e4f2f7b573337763e5c0013802e392818git ls-tree HEAD # 内部命令：显示某个git对象git rev-parse v2.0 # 内部命令：显示某个ref对于的SHA1 HASHgit reflog # 显示所有提交，包括孤立节点git show HEAD@&#123;5&#125;git show master@&#123;yesterday&#125; # 显示master分支昨天的状态git log --pretty=format:&#x27;%h %s&#x27; --graph # 图示提交日志git show HEAD~3git show -s --pretty=raw 2be7fcb476git stash # 暂存当前修改，将所有至为HEAD状态git stash list # 查看所有暂存git stash show -p stash@&#123;0&#125; # 参考第一次暂存git stash apply stash@&#123;0&#125; # 应用第一次暂存git grep &quot;delete from&quot; # 文件中搜索文本“delete from”git grep -e &#x27;#define&#x27; --and -e SORT_DIRENTgit gcgit fsck# 生成一个可供发布的压缩包$ git archive","categories":[{"name":"学习","slug":"学习","permalink":"https://carlsack.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://carlsack.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"代码","slug":"代码","permalink":"https://carlsack.github.io/tags/%E4%BB%A3%E7%A0%81/"}]},{"title":"图片索引","slug":"图片索引","date":"2024-01-31T09:30:54.000Z","updated":"2024-02-01T01:17:38.225Z","comments":true,"path":"2024/01/31/图片索引/","permalink":"https://carlsack.github.io/2024/01/31/%E5%9B%BE%E7%89%87%E7%B4%A2%E5%BC%95/","excerpt":"","text":"","categories":[],"tags":[]},{"title":"10个Nginx基本场景","slug":"10个Nginx基本场景","date":"2024-01-31T09:26:28.000Z","updated":"2024-02-01T02:34:23.540Z","comments":true,"path":"2024/01/31/10个Nginx基本场景/","permalink":"https://carlsack.github.io/2024/01/31/10%E4%B8%AANginx%E5%9F%BA%E6%9C%AC%E5%9C%BA%E6%99%AF/","excerpt":"","text":"10个Nginx基本场景 概述 安装&amp;使用 实用场景 虚拟主机- 静态站点- 反向代理- 负载均衡- HTTPS加密传输- 文件服务器- 限速- 限流- 黑白名单- 请求拦截 配置&amp;变量详解 HTTP状态码 概述What is Nginx?Nginx（发音同“engine x”）是一个高性能的反向代理和 Web 服务器软件，因其系统资源消耗低、运行稳定且具有高性能的并发处理能力等特性，Nginx 在互联网企业中得到广泛应用。 Nginx特点 高性能、高并发 扩展性好 异步非阻塞的事件驱动模型 Nginx Apache 一个进程处理多个请求 一个进程处理一个请求 非阻塞式 阻塞式 安装&amp;使用安装windows安装 下载官方稳定版：https://nginx.org/download/nginx-1.20.0.zip 解压到本地，直接运行nginx.exe即可 Linux安装 rpm包安装 ❝ rpm包下载页： http://nginx.org/packages/rhel/7/x86_64/RPMS/ ❞ 1$ rpm -ivh nginx-*.rpm 关闭防火墙 12$ firewall-cmd --zone=public --add-port=80/tcp --permanent$ firewall-cmd --reload rpm包中已包含了大量常用模块，推荐使用rpm包方式安装，简单快速 使用 命令参数 含义 nginx 启动 nginx -V 查看当前版本及编译配置信息 nginx -t 检查配置文件语法是否正确 nginx -s stop 直接关闭worker子进程 nginx -s quit 等待worker子进程正确处理完请求后关闭 nginx -s reload 重读配置文件 实用场景虚拟主机12345678910111213141516171819202122server &#123; # 1: 基于多ip的虚拟主机：listen监听不同网卡的ip，端口可相同 listen 8000; server_name 172.17.1.1; listen 8000; server_name 172.17.1.2; # 2: 基于多端口的虚拟主机：listen监听不同端口 listen 8001; server_name localhost; listen 8002; server_name localhost; #3: 基于域名的虚拟主机：端口可相同，server_name为不同域名 listen 8003; server_name www.test1.com; listen 8003; server_name www.test2.com;&#125; 静态站点为了加快网站解析速度，可以将动态资源交给后端服务器，纯前端的静态页面放在系统目录下，交给Nginx来解析。 123456789server &#123; listen 80; server_name localhost; location / &#123; root /opt/nginx/html; index index.html index.htm; &#125;&#125; 反向代理反向代理是用户客户端访问代理服务器后，被反向代理服务器按照一定的规则从一个或多个被代理服务器中获取响应资源并返回给客户端的代理模式，客户端只知道代理服务器的 IP，并不知道后端服务器的 IP，原因是代理服务器隐藏了被代理服务器的信息。 七层反向代理在配置文件nginx.conf中的http段中，写入如下格式的配置，即可将本地8088端口代理到百度： 12345678server &#123; listen 8088; server_name localhost; location / &#123; proxy_pass https://www.baidu.com; &#125;&#125; 四层反向代理Nginx除了可以代理HTTP七层流量，还可以代理 TCP&#x2F;UDP 四层流量，核心模块 stream 需要在编译配置时增加“–with-stream”参数进行编译（rpm包已包含）。 配置文件如下（需写在main段中）： 1234567stream &#123; server &#123; listen 3306; # 访问本机的3306，就被转发到了远程的3306 proxy_pass 172.17.0.1:3306; &#125;&#125; 负载均衡当出现高并发大流量的业务场景时，单台后端服务器已无法支撑业务正常运行，需要将请求流量按照一定规则分发到多台服务节点上，即使某个节点宕机，系统依然能够对外正常提供服务，以此来提高系统的性能和稳定性。 upstream模块 定义上游服务器 指令 含义 upstream 段名，中间定义上游服务url server 定义上游服务地址 zone 定义共享内存，用于跨worker子进程共享数据 keepalive 对上游服务启用长连接，每个worker子进程与上游服务器空闲长连接的最大数量（keepalive 16；当同时有5000个请求过来，处理完毕后，会保留16个连接，其他全部关闭） keepalive_requests 一个长连接可以处理的最多请求个数 keepalive_timeout 空闲情况下，一个长连接的超时时长，超过后会销毁长连接 hash 负载均衡算法：哈希 ip_hash 负载均衡算法：依据ip进行哈希计算 least_conn 负载均衡算法：最少连接数 least_time 负载均衡算法：最短响应时间 random 负载均衡算法：随机 server可选参数 参数 含义 weight&#x3D;number 权重值，默认为1 max_conns&#x3D;number 上游服务器的最大并发连接数 fail_timeout&#x3D;time 服务器不可用的判定时间（10s内不可用次数达3次，则在这10s内不会再转发给后端，超过10后依然还是会转发过去） max_fails&#x3D;number 服务器不可用的检查次数 backup 备份服务器，仅当其他服务器都不可用时 down 标记服务器长期不可用，离线维护 负载均衡算法 轮询（默认） 每个请求按时间顺序逐一分配到不同的后端服务器 123456upstream backend &#123; # 默认所有服务器权重为 1 server 192.168.1.1:8080; server 192.168.1.2:8080; server 192.168.1.3:8080;&#125; weight-权重轮询 指定轮询概率，用于后端服务器性能不均的情况 123456upstream backend &#123; server 192.168.1.1:8080 weight=3; server 192.168.1.2:8080 weight=2; # default weight=1 server 192.168.1.3:8080; &#125; 哈希-hash 哈希算法是将任意长度的二进制值映射为较短的固定长度的二进制值，这个小的二进制值叫哈希值，映射不可逆。- hash $request_uri：根据这个变量的哈希值来负载 123456upstream backend &#123; hash $request_uri; server 192.168.1.1:8080; server 192.168.1.2:8080; server 192.168.1.3:8080; &#125; ip_hash 每个请求按访问ip的hash结果分配，这样每个访客固定访问一个后端服务器，是session共享问题的解决方案之一 123456upstream backend &#123; ip_hash; server 192.168.1.1:8080; server 192.168.1.2:8080; server 192.168.1.3:8080; &#125; 最少连接数算法 多个worker子进程同时处理请求时，无法共享后端服务器的连接数状态，此时需要开辟共享内存空间，用来在多个worker子进程中共享信息- zone zone_name 1M，开辟共享内存 从上游服务器挑选一台当前已建立连接数最少的分配请求- 极端情况下会退化为轮询算法- least_conn： 123456upstream backend &#123; least_conn; server 192.168.1.1:8080; server 192.168.1.2:8080; server 192.168.1.3:8080; &#125; 「对上游服务器返回异常时的处理」 ❝ 「遇到这些情况下执行失败转发」 语法： 「proxy_next_upstream error」 | timeout | invalid_header | http_500 | http_502 | http_503 | http_504 | http_403 | http_404 | http_429 | non_idempotent| off 默认值：proxy_next_upstream error timeout 上下文：http, server, location 「超时时间，超过这个时间就不再尝试失败转发」 语法： 「proxy_next_upstream_timeout」 time 默认值：proxy_next_upstream_timeout 0 (不等待) 上下文：http, server, location 「转发次数」 语法： 「proxy_next_upstream_tries」 number 默认值：proxy_next_upstream_tries 0 (一直转发) 上下文：http, server, location ❞ 可选参数 含义 error 向后端服务器传输请求，或读取响应头「出错」时（服务器宕机会转发到下一台） timeout 向后端服务器传输请求，或读取响应头「超时」时（proxy_read_timeout设置的时间内没有接收完响应体，则会转发到下一台服务器；但是服务器宕机的话会返回502，不会转发下一台） invalid_header 后端返回无效的响应时 http_500、502、503、504、403、404、429 http响应状态为xxx时 non_idempotent 非幂等请求失败时，是否需要转发下一台后端服务器（不设置就是不转发，如post请求时，如果命中404，则会直接返回404。对于写操作最好不要轻易设置） off 禁用请求失败转发功能 配置样例123456789101112131415161718upstream backend &#123; zone upstream_backend 64k; server 127.0.0.1:8080 weight=2 max_conns=1000 fail_timeout=10s max_fails=5; server test.nginx.com weight=1; keepalive 16; keepalive_requests 100; keepalive_timeout 30s;&#125;server &#123; location /test &#123; proxy_pass http://backend/test; # 如果不配置proxy_next_upstream，当遇到上游返回http错误状态码时，nginx会直接返回给客户端 proxy_next_upstream error timeout invalid_header http_500 http_502 http_503 http_504 http_403 http_404 http_429; &#125;&#125; HTTPS加密传输HTTPS 通过加密通道保护客户端与服务端之间的数据传输，已成为当前网站部署的必选配置。在部署有 Nginx 代理集群的 HTTPS 站点，通常会把 SSL 证书部署在 Nginx 的服务器上，然后把请求代理到后端的上游服务器。这种部署方式由 Nginx 服务器负责 SSL 请求的运算，相对减轻了后端上游服务器的 CPU 运算量。 生成自签名HTTPS证书 12345678910111213# 配置https签名证书# 1、创建https证书存放目录：cd /usr/local/nginx/conf/mkdir ssl# 2、创建私钥：openssl genrsa -des3 -out https.key 1024# 3、创建签名请求证书：openssl req -new -key https.key -out https.csr# 4、在加载SSL支持的Nginx并使用上述私钥时除去必须的口令：cp https.key https.key.orgopenssl rsa -in https.key.org -out https.key# 5、最后标记证书使用上述私钥和CSR和有效期：openssl x509 -req -days 365 -in https.csr -signkey https.key -out https.crt server配置 1234567891011121314151617181920server &#123; listen 443 ssl; server_name localhost; # 证书部分 ssl_certificate /usr/local/nginx/conf/ssl/https.crt; #RSA证书 ssl_certificate_key /usr/local/nginx/conf/ssl/https.key; #RSA密钥 # TLS 握手优化 # 会话缓存的存储大小为1MB ssl_session_cache shared:SSL:1m; # 会话缓存的超时时间为5分钟 ssl_session_timeout 5m; keepalive_timeout 75s; keepalive_requests 100; location / &#123; root html; index index.html index.htm; &#125;&#125; 文件服务器要归档一些数据或资料，那么文件服务器必不可少。使用 Nginx 可以非常快速便捷的搭建一个简易的文件服务。 配置 123456789101112131415161718192021222324252627282930server &#123; listen 8004; server_name localhost; # 正常显示中文，windows服务器下中文目录无法下钻，目前无解 charset gbk,utf-8; # 打开autoindex功能，以/结尾的请求 autoindex on; # 显示文件的大小， # on：以字节显示 # off：人性化显示，文件过大会显示为mb或gb autoindex_exact_size off; # 以哪种格式返回：html | xml | json | jsonp # 默认值：autoindex_format html autoindex_format html; # 显示时间格式 # on: 12-Jul-2019 10:11（当前时区） # off: 12-Jul-2019 02:11(0时区，GMT) autoindex_localtime on; location / &#123; root /data/files/; # 如果a.html文件存在，则会返回a.html内容，否则才会返回目录内容 index a.html; &#125; &#125; 限速1234567891011121314location /rate &#123; # 定义响应数据的传输速度，默认bytes/s limit_rate 20; # 这些是Nginx处理请求时相关变量，加大返回数据量更好地看到限速效果 return 200 &#x27;request_time $request_timerequest_id $request_idserver_name $server_namerequest_filename $request_filenamedocument_root $document_rootrealpath_root $realpath_rootrequest_completion $request_completion&#x27;;&#125; 限流limit_conn 用于限制客户端并发连接数 使用共享内存，对所有的worker子进程生效（需要保存客户端连接数） limit_req 用于限制客户端处理请求的「平均速率」 使用共享内存，对所有的worker子进程生效 限流算法：「leaky_bucket」（漏桶） 暂时拦截住上方水的向下流动，等待桶中的一部分水漏走后，再放行上方水。- 溢出的上方水直接抛弃。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263http &#123; include mime.types; default_type application/json; # limit_conn_zone key zone=name:size # key：用于定义客户端的唯一标识来限速，如remote_addr # name：任意名称 # size：共享内存大小空间，m为单位 # binary_remote_addr 使用4个字节空间，高效;remote_addr 使用7-15个字节空间 limit_conn_zone $binary_remote_addr zone=limit_addr:10m; # limit_req_zone key zone=name:size rate=rate; # 上下文：http # rate:表示允许相同标识的客户端的访问频次，12r/m的，即限制每5秒访问一次，每5秒才处理一个请求。 limit_req_zone $binary_remote_addr zone=limit_req:15m rate=12r/m; server &#123; listen 80; server_name localhost; location / &#123; root html; index index.html index.htm; # 触发限速后，返回状态码,默认503 # 上下文：http, server, location limit_conn_status 503; # 当触发限速后，错误日志出记录一条日志， 这里用于定义日志等级 # info|notice|warn|error # 上下文：http, server, location # 默认值：error limit_conn_log_level warn; # limit_conn zone number; # zone：用limit_conn_zone中定义的zone名称 # number：以zone为标识的客户端被允许的同时最大连接数 limit_conn limit_addr 2; # 定义响应数据的传输速度，bytes/s # 本指令属于ngx_http_core_module，不属于ngx_http_limit_conn_module limit_rate 50; # limit_req_status code（http的状态码） # 默认值：503 # 上下文：http, server, location limit_req_status 504; # 触发限速后，日志记录的等级 # info|notice|warn|error # 默认值：error # 上下文：http, server, location limit_req_log_level notice; # limit_req zone=name [burst=number] [nodelay | delay=number]; # burst：桶大小,设置一个大小为x的缓冲区,当有大量请求（爆发）过来时，超过了访问频次限制的请求可以先放到这个缓冲区内等待，但是这个等待区里的位置只有5个，超过的请求会直接报503的错误然后返回。 # nodelay：如果设置，会在瞬时提供处理(burst + rate)个请求的能力，请求超过（burst + rate）的时候就会直接返回503，永远不存在请求需要等待的情况。 # 上下文：http, server, location # limit_req zone=limit_req burst=7 nodelay; limit_req zone=limit_req; &#125; &#125;&#125; 黑白名单access 限制特定IP或网段访问 allow deny 123456789101112131415server &#123; listen 80; server_name localhost; location / &#123; # allow address | CIDR | UNIX | all # 默认值 # 上下文：http, server, location, limit_except allow 192.168.0.1/24; # deny address | CIDR | UNIX | all # 默认值 # 上下文：http, server, location, limit_except deny all; &#125;&#125; 规则示例123456789101112131415161718location / &#123; # 规则从上到下 # 拒绝 deny 192.168.1.1; # 放行192.168.1.0网段，子网掩码24位（255.255.255.0），但是除了192.168.1.1 allow 192.168.1.0/24; # 放行10.1.1.0网段，子网掩码16位（255.255.0.0） allow 10.1.1.0/16; # 放行ipv6 allow 2001:0db8::/32; # 除了上面放行的，其他全部拒绝 deny all;&#125; 请求拦截auth_request 基于子请求收到的HTTP响应码做访问控制 如：拦截所有请求，先去做鉴权请求，通过后再放行 1234567891011121314location /private &#123; # 默认值：off # 上下文：http, server, location; # 鉴权成功对会返回后面实际内容，鉴权失败会返回鉴权服务的返回内容 auth_request /auth; ...&#125;location /auth &#123; proxy_pass http://localhost:8080/auth; proxy_pass_request_body off; proxy_set_header Content-Length &quot;&quot;; proxy_set_header X-Original-URI $request_uri; &#125; 配置&amp;变量详解全局配置main段12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152核心参数（其他参数大部分情况下用不到）# user USERNAME [GROUP]# 解释：指定运行nginx的worker子进程的属主和属组，其中属组可以不指定user nginx;# worker_processes NUMBER | auto# 解释：指定nginx启动的worker子进程数量# 【*auto：自动设置为物理CPU核心数】worker_processes auto;# pid DIR# 解释：指定运行nginx的master主进程的pid文件存放路径pid /opt/nginx/logs/nginx.pid;# worker_rlimit_nofile NUMBER# 解释：指定worker子进程可以打开的最大文件句柄数# 【系统最大打开65535，每个子进程打开数乘子进程数，实际也不会超过65535】# 这个值需要调大worker_rlimit_nofile 20480;# worker_rlimit_core SIZE# 指定worker子进程异常终止后的core文件，用于记录分析问题worker_rlimit_core 50M;working_directory /opt/nginx/tmp;#【必须对子进程用户赋写权限】# 解释：将每个worker子进程与CPU物理核心绑定# 【master负责调度，worker负责处理请求】# 【假设CPU有4个核心，某一时刻worker1获取到了CPU1的工作调度时间片，时间片过后worker1从CPU1上面撤下来，CPU1去处理其他事件，下一时刻可能是CPU2、CPU3的时间片调度到了worker1上面，那么worker1就会在其他CPU上面工作，进程与CPU的调度切换是有损耗的，worker1如果绑定了CPU1，worker1将永远等待CPU1的调度，充分利用CPU缓存】# 【【主要作用：将每个worker子进程与特定CPU物理核心绑定，优势在于：避免同一个worker子进程在不同的CPU核心上切换，缓存失效，降低性能；其并不能真正避免进程切换（进程切换是CPU工作特性）】】# -- worker_cpu_affinity 00000001 00000010 00000100 00001000 00010000 00100000 01000000 10000000;# 8核心，8个worker# -- worker_cpu_affinity 01 10 01 10;# 2核心，4个workerworker_cpu_affinity 0001 0010 0100 1000;# 4核心，4个worker# 解释：指定worker子进程的nice值，以调整运行nginx的优先级，通常设定为“负值”，以优先调用nginx# 【Linux默认进程的优先级值是120，值越小越优先；nice设定范围为-20到+19】# 【对Linux来说，优先级值则是100到139】worker_priority -20;# 指定worker子进程优雅退出时的超时时间，不管5秒内是否处理完，都强制退出worker_shutdown_timeout 5s;# worker子进程内部使用的计时器精度，调整时间间隔越大，系统调用越少，有利于性能提升；反之，系统调用越多，性能下降# 比如某些计时的操作，worker需要去获取内核时间，频繁跟内核打交道会降低性能timer_resolution 100ms;# daemon on | off# 设定nginx的运行方式，前台还是后台，前台用户调试，后台用于生产daemon on;# 负载均衡互斥锁文件存放路径lock_file logs/nginx.lock; events段12345678910111213141516events &#123; # Nginx使用何种事件驱动模型,一般不指定这个参数 # use epoll; # worker子进程能够处理的最大并发连接数，多核情况最大其实达不到65535， worker_connections 65535; # 是否打开负载均衡互斥锁，默认off（当master接收到请求时，会给每个worker发送消息去唤醒，状态为on时，则会有一个负载均衡锁，master会轮流发给每一个） accept_mutex on; # 新连接分配给worker子进程的超时时间，默认500ms，超时后会转给下一个worker处理请求 accept_mutex_delay 100ms; # worker子进程可以接收的新连接个数(这个参数对性能影响不太大) multi_accept on;&#125; http段 server段 12345678910111213141516server &#123; listen 80; server_name www.test.com; location /picture &#123; root /opt/nginx/html/picture; # 客户端请求 www.test.com/picture/1.jpg； # 对应磁盘映射路径为：/opt/nginx/html/picture/picture/1.jpg &#125; location /picture &#123; alias /opt/nginx/html/picture/; # 客户端请求 www.test.com/picture/1.jpg； # 对应磁盘映射路径为：/opt/nginx/html/picture/1.jpg # 【末尾一定要加/】 &#125;&#125; server_name的匹配规则 1234567891011121314# 精确匹配，优先级最高，1server_name www.test.com;# 左通配，优先级2server_name *.test.com;# 右通配，优先级3server_name www.test.*;# 正则通配，优先级最低，4server_name ~^w\\.test\\..*$;# 多个server_name www.test.com *.test.com www.test.* ~^w\\.test\\..*$; location段 匹配规则 含义 示例 优先级（1最高） &#x3D; 精确匹配 location &#x3D; &#x2F;pic&#x2F; 1 ^~ 匹配到即停止搜索 location ^~ &#x2F;pic&#x2F; 2 ~ 正则匹配，区分大小写 location ~ .(Jpg|gif)# 3 ~* 正则匹配，不区分大小写 location ~ .(Jpg|gif)$ 4 无符号 location &#x2F; 5 @ 内部跳转 location @errorpage 12345678910111213141516171819# 测试样例location ~ /test/8005/t/$ &#123; return 200 &#x27;first regular expressions match!&#x27;;&#125;location ~* /test/8005/t/(\\w+)$ &#123; return 200 &#x27;longest regular expressions match!&#x27;;&#125;location ^~ /test/8005/t/ &#123; return 200 &#x27;stop regular expressions match!&#x27;;&#125;location /test/8005/t/Test2 &#123; return 200 &#x27;longest prefix string match!&#x27;;&#125;location /test/8005/t &#123; return 200 &#x27;prefix string match!&#x27;;&#125;location = /test/8005/t &#123; return 200 &#x27;exact match!&#x27;;&#125; root与alias的区别 root alias 语法 root path alias path 上下文 http, server, location, if location 区别 将定义路径与URI叠加 只取定义路径，末尾一定要加&#x2F; location末尾带与不带&#x2F;的区别 不带&#x2F; location &#x2F;test 尝试把test当成目录，如果找不到则找test文件 带&#x2F; location &#x2F;test&#x2F; 将test作为目录，如果不存在则直接返回404 123456789location /status &#123; # 监控模块 stub_status;&#125;# ------页面结果------Active connections: 2 server accepts handled requests 16 16 26 Reading: 0 Writing: 1 Waiting: 1 状态项 含义 Active connections 当前客户端与Nginx间的TCP连接数，等于下面Reading、Writing、Waiting数量之和 accepts 自Nginx启动起，与客户端建立过的连接总数 handled 自Nginx启动起，处理过的客户端连接总数。如果没有超出worker_connections配置，该值与accepts相同 requests 自Nginx启动起，处理过的客户端请求总数。由于存在HTTP Keep-Alive请求，故requests值会大于handled值 Reading 正在读取HTTP请求头部的连接总数 Writing 正在向客户端发送响应数据的连接总数 Waiting 当前空闲的HTTP Keep-Alive连接总数 内嵌变量 变量名 含义 $connections_active 同Active connections值 $connections_reading 同Reading值 $connections_writing 同Writing值 $connections_waiting 同waiting值 rewrite指令&amp;return指令 根据指定正则表达式匹配规则，重写URL 停止处理请求，直接返回响应码或重定向到其他URL- 执行return指令后，location中后续指令将不会被执行 return- rewrite 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162location / &#123; # 上下文：server, location, if # return code [text]; # text：响应体内容（如果code是200） # return 200 &quot;return 200 HTTP Code&quot;; # return code URL; # URL：重定向 # return 302 /test; # return URL; # URL:直接跟URL的话必须是http/https开头的完整路径 # text：响应体内容 return http://localhost:8000/test;&#125;location /test &#123; index test.html;&#125;location /search &#123; # rewrite regex replacement [flag] # 上下文：server, location, if # flag: # last: 重写后的url发起新请求，再次进入server段，重试location中的匹配 # break: 直接使用重写后的url，不再匹配其他location中的语句 # redirect: 返回302临时重定向 # permanent: 返回301永久重定向 rewrite /(.*) https://www.baidu.com permanent;&#125;location /test1 &#123; # 继续匹配location， rewrite /images/(.*) /test2/$1 last; return 200 &quot;return 200 in /test1&quot;;&#125;location /test2 &#123; # 不会再匹配，直接找test3下面的文件 rewrite /pics/(.*) /test3/$1 break; return 200 &quot;return 200 in /test2&quot;;&#125;location /test3 &#123; # 请求：/test3/index.html, # 结果：直接返回&quot;return 200 in /test3&quot;，不会再去找index.html文件 return 200 &quot;return 200 in /test3&quot;;&#125;location /test4/ &#123; if ( $remote_addr = &quot;192.168.1.1&quot; ) &#123; return 200 &quot;test if OK in URL /test4/&quot;; &#125; &#125;location /test5 &#123; if ( $uri = &quot;/images/&quot; ) &#123; rewrite (.*) /test2/ break; &#125; # 执行了上面rewrite后，这里的return还会执行，通常不会联合一起写 return 200 &quot;test5 if failed\\n&quot;;&#125; Nginx变量分类1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798991001011021031041051061071081091101111121131141151161171181191201211221231241251261271281291301311321331341351361371381391401411421431441451、TCP连接相关变量 #客户端地址，例如192.168.1.1 remote_addr #客户端端口，例如58473 remote_port #客户端地址的整型格式 binary_remote_addr #已处理连接，是一个递增的序号 connection #当前连接上执行的请求数，对于keepalive连接有意义 connection_request #如果使用proxy_protocol协议，则返回原始用户的地址，否则为空 proxy_protocol_addr #如果使用proxy_protocol协议，则返回原始用户的端口，否则为空 proxy_protocol_port #服务器地址，例如192.168.184.240 server_addr #服务器端口,例如80 server_port #服务端协议，例如HTTP/1.1 server_protocol 2、HTTP请求相关变量 #请求包体头部长度 conten_length #请求包体类型 content_type #URL中某个参数 arg_参数名 #所有URL参数 args #URL中有参数，则返回?；否则返回空 is_args #与args完全相同 query_string #请求的URL，不包含参数 uri #请求的URL，包含参数 request_uri #协议名，http或者https scheme #请求的方法，GET、HEAD、POST等 request_method #所有请求内容的大小，包含请求行，头部，请求体 request_length #由HTTP Basic Authentication协议传入的用户名 remote_user #客户端请求主体信息的临时文件名 request_body_file #包含请求的主要信息，在使用proxy_pass或fastcgi_pass指令的location中比较有意义 request_body #先看请求行，再看请求头，最后找server_name host #用户浏览器标识 http_user_agent #从哪些链接过来的请求 http_referer #经过一层代表服务器，添加对应代理服务器的信息 http_via #获取用户真实IP http_x_forwarded_for #用户cookie http_cookie 3、Nginx处理请求时相关变量 #请求处理到现在所耗费的时间，单位为秒，例如0.03代表30毫秒 request_time #请求处理完成，则返回OK，否则为空 request_completion #16进制显示的请求id，随机生成的 request_id #匹配上请求的server_name值 server_name #若开启https，则值为on,否则为空 https #待访问文件的完整路径 request_filename #由URI和root/alias规则生成的文件夹路径 document_root #将document_root中的软链接换成真实路径 realpath_root #返回响应时的速度上限值 limit_rate 4、Nginx返回响应时相关变量 #响应体中真实内容的大小 body_bytes_sent #全部响应体大小 body_sent #HTTP返回状态码 status 5、系统变量 #nginx系统版本 nginx_version #服务器时间 time_local 时间空间单位时间单位 ms：毫秒 s：秒 m：分钟 h：小时 d：天 w：周 M：月 y：年 空间单位 k&#x2F;K：KB m&#x2F;M：MB g&#x2F;G：GB HTTP状态码 分类 描述 1** 信息，服务器收到请求，需要请求者继续执行操作 2** 成功，操作被成功接收并处理 3** 重定向，需要进一步的操作以完成请求 4** 客户端错误，请求包含语法错误或无法完成请求 5** 服务器错误，服务器在处理请求的过程中发生了错误 状态码 描述 100 继续。客户端应继续其请求 101 切换协议。服务器根据客户端的请求切换协议。只能切换到更高级的协议，例如，切换到HTTP的新版本协议 200 请求成功。一般用于GET与POST请求 201 已创建。成功请求并创建了新的资源 202 已接受。已经接受请求，但未处理完成 203 非授权信息。请求成功。但返回的meta信息不在原始的服务器，而是一个副本 204 无内容。服务器成功处理，但未返回内容。在未更新网页的情况下，可确保浏览器继续显示当前文档 205 重置内容。服务器处理成功，用户终端（例如：浏览器）应重置文档视图。可通过此返回码清除浏览器的表单域 206 部分内容。服务器成功处理了部分GET请求 300 多种选择。请求的资源可包括多个位置，相应可返回一个资源特征与地址的列表用于用户终端（例如：浏览器）选择 301 永久移动。请求的资源已被永久的移动到新URI，返回信息会包括新的URI，浏览器会自动定向到新URI。今后任何新的请求都应使用新的URI代替 302 临时移动。与301类似。但资源只是临时被移动。客户端应继续使用原有URI 303 查看其它地址。与301类似。使用GET和POST请求查看 304 未修改。所请求的资源未修改，服务器返回此状态码时，不会返回任何资源。客户端通常会缓存访问过的资源，通过提供一个头信息指出客户端希望只返回在指定日期之后修改的资源 305 使用代理。所请求的资源必须通过代理访问 306 已经被废弃的HTTP状态码 307 临时重定向。与302类似。使用GET请求重定向 400 客户端请求的语法错误，服务器无法理解 401 请求要求用户的身份认证 402 保留，将来使用 403 服务器理解请求客户端的请求，但是拒绝执行此请求 404 服务器无法根据客户端的请求找到资源（网页）。通过此代码，网站设计人员可设置”您所请求的资源无法找到”的个性页面 405 客户端请求中的方法被禁止 406 服务器无法根据客户端请求的内容特性完成请求 407 请求要求代理的身份认证，与401类似，但请求者应当使用代理进行授权 408 服务器等待客户端发送的请求时间过长，超时 409 服务器完成客户端的 PUT 请求时可能返回此代码，服务器处理请求时发生了冲突 410 客户端请求的资源已经不存在。410不同于404，如果资源以前有现在被永久删除了可使用410代码，网站设计人员可通过301代码指定资源的新位置 411 服务器无法处理客户端发送的不带Content-Length的请求信息 412 客户端请求信息的先决条件错误 413 由于请求的实体过大，服务器无法处理，因此拒绝请求。为防止客户端的连续请求，服务器可能会关闭连接。如果只是服务器暂时无法处理，则会包含一个Retry-After的响应信息 414 请求的URI过长（URI通常为网址），服务器无法处理 415 服务器无法处理请求附带的媒体格式 416 客户端请求的范围无效 417 服务器无法满足Expect的请求头信息 500 服务器内部错误，无法完成请求 501 服务器不支持请求的功能，无法完成请求 502 作为网关或者代理工作的服务器尝试执行请求时，从远程服务器接收到了一个无效的响应 503 由于超载或系统维护，服务器暂时的无法处理客户端的请求。延时的长度可包含在服务器的Retry-After头信息中 504 充当网关或代理的服务器，未及时从远端服务器获取请求 505 服务器不支持请求的HTTP协议的版本，无法完成处理","categories":[{"name":"学习","slug":"学习","permalink":"https://carlsack.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"代理","slug":"代理","permalink":"https://carlsack.github.io/tags/%E4%BB%A3%E7%90%86/"}]},{"title":"Prometheus 基础介绍","slug":"promethus基础","date":"2023-08-03T07:35:21.000Z","updated":"2023-08-16T14:35:15.270Z","comments":true,"path":"2023/08/03/promethus基础/","permalink":"https://carlsack.github.io/2023/08/03/promethus%E5%9F%BA%E7%A1%80/","excerpt":"","text":"Prometheus监控系统什么是Prometheus?Prometheus是由SoundCloud开发的开源监控报警系统和时序列数据库(TSDB)。Prometheus使用Go语言开发，是Google BorgMon监控系统的开源版本。2016年由Google发起Linux基金会旗下的原生云基金会(Cloud Native Computing Foundation), 将Prometheus纳入其下第二大开源项目。Prometheus目前在开源社区相当活跃。Prometheus和Heapster(Heapster是K8S的一个子项目，用于获取集群的性能数据。)相比功能更完善、更全面。Prometheus性能也足够支撑上万台规模的集群。 Prometheus的特点 多维度数据模型。 灵活的查询语言。 不依赖分布式存储，单个服务器节点是自主的。 通过基于HTTP的pull方式采集时序数据。 可以通过中间网关进行时序列数据推送。 通过服务发现或者静态配置来发现目标服务对象。 支持多种多样的图表和界面展示，比如Grafana等。 官网地址：https://prometheus.io/ 架构图 基本原理Prometheus的基本原理是通过HTTP协议周期性抓取被监控组件的状态，任意组件只要提供对应的HTTP接口就可以接入监控。不需要任何SDK或者其他的集成过程。这样做非常适合做虚拟化环境监控系统，比如VM、Docker、Kubernetes等。输出被监控组件信息的HTTP接口被叫做exporter 。目前互联网公司常用的组件大部分都有exporter可以直接使用，比如Varnish、Haproxy、Nginx、MySQL、Linux系统信息(包括磁盘、内存、CPU、网络等等)。 服务过程 Prometheus Daemon负责定时去目标上抓取metrics(指标)数据，每个抓取目标需要暴露一个http服务的接口给它定时抓取。Prometheus支持通过配置文件、文本文件、Zookeeper、Consul、DNS SRV Lookup等方式指定抓取目标。Prometheus采用PULL的方式进行监控，即服务器可以直接通过目标PULL数据或者间接地通过中间网关来Push数据。 Prometheus在本地存储抓取的所有数据，并通过一定规则进行清理和整理数据，并把得到的结果存储到新的时间序列中。 Prometheus通过PromQL和其他API可视化地展示收集的数据。Prometheus支持很多方式的图表可视化，例如Grafana、自带的Promdash以及自身提供的模版引擎等等。Prometheus还提供HTTP API的查询方式，自定义所需要的输出。 PushGateway支持Client主动推送metrics到PushGateway，而Prometheus只是定时去Gateway上抓取数据。 Alertmanager是独立于Prometheus的一个组件，可以支持Prometheus的查询语句，提供十分灵活的报警方式。 三大套件 Server 主要负责数据采集和存储，提供PromQL查询语言的支持。 Alertmanager 警告管理器，用来进行报警。 Push Gateway 支持临时性Job主动推送指标的中间网关。 启动prometheus1nohup ./prometheus 1&gt;/dev/null 2&gt;&amp;1 &amp; 监控指标介绍Prometheus监控数据格式 1、Prometheus metrics的概念 2、k&#x2F;v的数据形式 3、Prometheus exporter的使用（pull形式采集数据） 4、Prometheus pushgateway的入门介绍（push形式采集数据） Prometheus监控中，对于采集过来的数据，统一称为metrics数据 Metrics，熟悉大数据系统的不可能没听过说过metrics，当我们需要为某个系统某个服务做监控、做统计，就需要用到Metrics。 Metrics是一种采样数据的总称（metrics并不代表某一种具体的数据格式，是一种对于度量计算单位的抽象） metrics的几种主要的类型Gauges类型 最简单的度量指标，只有一个简单的返回值，或者叫瞬时状态，例如，我们想衡量一个的处理队列中任务的个数用更简单的方式举个例子 例如：如果我要监控硬盘容量或者内存的使用量，那么就应该使用Gauges的metrics格式来度量 因为硬盘的容量或者内存的使用量是随着时间的推移不断的瞬时 没有规则的 变化 这种变化没有规律，当前是多少，采集回来就是多少 既不能肯定是 一直持续增长，也不能肯定是一直降低 是多少就是多少，这种就是Gauges使用类型的代表 如图所示CPU的上下浮动就是采集使用Gauge形式的 metrics数据 没有规律 Counters类型 Counter就是计数器，从数据量0开始累计计算，在理想状态下，只能是永远的增持，不会降低（一些特殊情况另说） 举个例子来说 比如对用户访问量的采样数据 我们的产品被用户访问一次就是1过了10分钟后积累到100 过一天后积累到20000 一周后积累到100000-150000 如下图展示的。Counter数据 是从0开始，一直不断的积累，累加下去的，所以理想状态下，不可能出现任何降低的状况 最多只可能是一只保持不变（例如：用户不在访问了，那么当前累积的总访问量，会以一条水平线的状态保持下去，直到再次被访问） 如下图展示的就是一个counter类型的metrics数据采集。采集的是用户的访问累积量 Histograms类型 Histograms统计数据的分布情况。比如最小值，最大值，中间值，还有中位数，75百分位，90百分位，95百分位，98百分位，99百分位，和99.9百分位的值（percentiles）。 这是一种特殊的metrics数据类型，代表的是一种 近似的百分比估算数值 介绍什么是Histogram数据 histogram类型（prometheus中，其实提供了一个基于histogram算法的函数可以直接使用）可以分别统计出全部用户的响应时间中&#x3D;0.05秒的量有多少 00.05秒的有多少，&gt;2秒的有多少 &gt;10秒的有多少&#x3D;&gt;1% 可以很清晰的看到当前系统中，处于基本正常状态的有多少百分比的用户（或者是请求）多少处于速度极快的用户，多少处于慢请求或者有问题的请求 k&#x2F;v的数据形式Prometheus的数据类型就是依赖于 metrics的类型来计算的 而对于采集回来的数据类型，必须要以一种具体的数据格式供查看和使用 看一下一个exporter采集来的服务器上的k&#x2F;v形式metrics数据 当一个exporter（node_exporter）被安装和运行在被监控的服务器上后 使用简单的curl命令就可以看到exporter采集到的metrics数据的样子，以k&#x2F;v的形式展现和保存 curl localhost:9100&#x2F;metrics 如上图所示curl之后的结果输出 Prometheus_server 带#的行是注释行用来解释下面这一项k&#x2F;v数值 是什么采样的数据 而真正关心的是数据 用空格分开KEY&#x2F;Value数据 第一个代表的是当前采集的最大文件句柄数是65535 第二个代表的是当前采集的被打开的文件句柄数是10 另外 再看下这里 第二行#告诉我们了这一项数据的metrics类型属于gauge exporter的使用官网提供了丰富的成型exporter插件可以使用 举几个例子 pushgateway的概念介绍 exporter是首先安装在被监控服务器上运行在后台 然后自动采集系统数据，本身又是一个HTTP_server可以被Prometheus服务器 定时去HTTP GET取得数据属于pull的形式 如果把这个过程反过来 push的形式十八pushgatewat安装在客户端或者服务端（其实装哪里都无所谓） pushgateway本身也是一个http服务器 运维通过自己的脚本程序 抓自己想要的监控数据，然后推送到pushgateway再由pushgateway推送到prometheus服务端是一个反过来的被动模式 已经有了那么强大的pull形式的node_exporter采集，为什么还需要一个pushgateway的形式呢？ 1、exporter虽然采集类型已经很丰富了，但是我们依然需要很多自制的监控数据，非规则化的自定制的 2、exporter由于数据类型采集量大，其实很多数据或者说大部分数据其实我们监控中真的用不到，用pushgateway是定义一项数据就采集着一种节省资源 3、一个新的自定义的pushgateway脚本开发远远比开发一个全新的exporter简单快速的多的多！！！（exporter的开发需要使用真正的编程语言，shell这种快速脚本是不行的，而且需要了解很多Prometheus自定义的编程格式才能开始制作工作量很大） 4、exporter虽然已经很丰富了，但是依然有很多的我们需要的采集形式，exporter无法提供，或者说现有的expoter还不支持，但是如果使用pushgateway的形式就可以任意灵活想做什么都可以做到，而且极快 内存指标介绍内存指标有 VSS、RSS、PSS、USS，他们的含义分别是： VSS：Virtual Set Size 虚拟耗用内存（包含共享库占用的内存） RSS：Resident Set Size 实际使用物理内存（包含共享库占用的内存） PSS：Proportional Set Size 实际使用的物理内存（按比例分配共享库占用的内存） USS：Unique Set Size 进程独自占用的物理内存（不包含共享库占用的内存） 一般来说内存占用大小有如下规律：VSS &gt;&#x3D; RSS &gt;&#x3D; PSS &gt;&#x3D; USS，一般测试中关注的比较多的是 PSS 这个指标。 容器监控cadvisor 的安装使用 docker pull 下载最新版本的 cadvisor docker pull google&#x2F;cadvisor:latest 使用 docker run 启动 （建议放在脚本中启动 vi cadvisor-start.sh） 12345678910docker run \\ --volume=/:/rootfs:ro \\ --volume=/var/run:/var/run:rw \\ --volume=/sys:/sys:ro \\ --volume=/var/lib/docker/:/var/lib/docker:ro \\ --volume=/dev/disk/:/dev/disk:ro \\ --publish=18104:8080\\ --detach=true \\ --name=cadvisor \\ google/cadvisor:latest 当启动成功后，使用 docker ps 你会看到 cadvisor 的启动情况 windows监控 windows_exporter 支持 Windows Server 2008R2 以及之后的版本, 和桌面版本的 Windows 7 以及之后的版本 Linux监控 node_exporter grafana 图形化监控centos安装grafana12wget https://dl.grafana.com/oss/release/grafana-8.0.3-1.x86_64.rpmsudo yum install grafana-8.0.3-1.x86_64.rpm PromSQL语法1.获取cpu使用率1100-(avg(irate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by(instance) *100) 其中irate函数:irate取的是在指定时间范围内的最近两个数据点来算速率 其中by函数相当于关系型数据库中的group by函数 2.获取内存使用率1100-(node_memory_MemFree_bytes+node_memory_Buffers_bytes+node_memory_Cached_bytes)/node_memory_MemTotal_bytes*100 3.count函数用于进行统计或者进行判断,比如判断值大小,为真返回1,否则返回null,no data cpu使用率: 1100-(avg(irate(node_cpu_seconds_total&#123;mode=&quot;idle&quot;&#125;[5m])) by(instance) *100) 内存使用率： 1100 - (node_memory_MemFree_bytes+node_memory_Buffers_bytes+node_memory_Cached_bytes)/node_memory_MemTotal_bytes*100 硬盘使用率： 1100-node_filesystem_free_bytes&#123;mountpoint=&quot;/&quot;,fstype=~&quot;ext4|rootfs&quot;&#125;/node_filesystem_size_bytes&#123;mountpoint=&quot;/&quot;,fstype=~&quot;ext4|rootfs&quot;&#125;*100 监控systemctl管理的系统服务运行状态 1./node_exporter --collector.systemd --collector.systemd.unit-whitelist=(logstash|docker|sshd).service PromQL查询node_systemd_unit_state可以看到服务的运行状态 [附录1]基于docker封装prometheus解决时区问题一、概述官方dockerhub上面的prometheus，下载命令如下： docker pull prom&#x2F;prometheus 发现它的时区为：UTC，我需要更改为CST，也就是中国上海时区。 发现修改变量TZ&#x3D;Asia&#x2F;Shanghai，修改&#x2F;etc&#x2F;localtime 文件都无法修改时区，均失败了。 那么解决办法，就只有自己封装prometheus镜像了。 二、启动prometheus环境说明 操作系统：centos 7.6 docker版本：20.10.7 ip地址：192.168.0.107 封装prometheus目录结构新建目录&#x2F;opt&#x2F;myprometheus，目录结构如下： 123./├── dockerfile└── prometheus-2.28.0.linux-amd64.tar.gz dockerfile内容 12345678910111213FROM centos:7ADD prometheus-2.28.0.linux-amd64.tar.gz /RUN ln -snf /usr/share/zoneinfo/Asia/Shanghai /etc/localtime &amp;&amp; \\ mv /prometheus-2.28.0.linux-amd64 /prometheusWORKDIR /prometheusENTRYPOINT [ &quot;/prometheus/prometheus&quot; ]CMD [ &quot;--config.file=/prometheus/prometheus.yml&quot;, \\ &quot;--storage.tsdb.path=/prometheus/data&quot;, \\ &quot;--web.console.libraries=/prometheus/console_libraries&quot;, \\ &quot;--web.enable-lifecycle&quot;, \\ &quot;--web.console.templates=/prometheus/consoles&quot; ] prometheus-2.28.0.linux-amd64.tar.gz 是从官方下载的，链接如下：https://prometheus.io/download/ 生成镜像1docker build -t myprometheus:v1 . 启动镜像创建持久化目录1mkdir -p /data/prometheus 后台启动12345docker run -d \\ --restart=always \\ --name prometheus \\ -p 9090:9090 \\ myprometheus:v1 等待几秒，拷贝容器文件1docker cp prometheus:/prometheus/ /data/prometheus 删除容器1docker rm -f prometheus 挂载目录启动123456docker run -d \\ --restart=always \\ --name prometheus \\ -p 9090:9090 \\ -v /data/prometheus:/prometheus \\ myprometheus:v1 查看时区1234docker exec -it prometheus dateThu Jul 30 17:54:37 CST 2020 发现时区是正确的。 访问页面http://192.168.0.107:9090 另外再介绍一下alertmanager修改时区，镜像下载命令为： 1docker pull prom/alertmanager 那么启动命令为： 12345678910mkdir -p /data/alertmanager /data/alertmanager/storagedocker run -d \\ -p 9093:9093 \\ --name alertmanager \\ --restart=always \\ -v /etc/localtime:/etc/localtime \\ -v /data/alertmanager:/etc/alertmanager \\ -v /data/alertmanager/storage:/alertmanager \\ prom/alertmanager 这里直接将&#x2F;etc&#x2F;localtime文件，挂载一下即可。 [附录2]consul服务发现问题 会发现 Prometheus 同时加载出来了默认服务 consul，这个是不需要的。 默认只显示 job 及 instance 两个标签，其他标签都默认属于 before relabeling 下，有些必要的服务信息，也想要在标签中展示，该如何操作呢？ 如果需要自定义一些标签，例如 team、group、project 等关键分组信息，方便后边 alertmanager 进行告警规则匹配，该如何处理呢？ 所有 Consul 中注册的 Service 都会默认加载到 Prometheus 下配置的 consul_prometheus 组，如果有多种类型的 exporter，如何在Prometheus 中配置分配给指定类型的组，方便直观的区别它们？ [附录3] consul 服务注册，依赖于json文件123456789101112131415161718192021222324[root@prometheus consul]# cat node-example.json&#123; &quot;ID&quot;: &quot;node-exporter-192.168.31.132&quot;, &quot;Name&quot;: &quot;node-exporter-192.168.31.132&quot;, &quot;Tags&quot;: [ &quot;node-exporter&quot; ], &quot;Address&quot;: &quot;192.168.31.132&quot;, &quot;Port&quot;: 9100, &quot;Meta&quot;: &#123; &quot;app&quot;: &quot;Linux&quot;, &quot;team&quot;: &quot;cloudgroup&quot;, &quot;project&quot;: &quot;Linux-service&quot; &#125;, &quot;EnableTagOverride&quot;: false, &quot;Check&quot;: &#123; &quot;HTTP&quot;: &quot;http://192.168.31.132:9100/metrics&quot;, &quot;Interval&quot;: &quot;5s&quot; &#125;, &quot;Weights&quot;: &#123; &quot;Passing&quot;: 10, &quot;Warning&quot;: 1 &#125;&#125; 1234567891011121314151617181920212223242526[root@prometheus consul]# cat docker-example.json&#123; &quot;ID&quot;: &quot;cadvisor-exporter-192.168.31.138&quot;, &quot;Name&quot;: &quot;cadvisor-exporter-192.168.31.138&quot;, &quot;Tags&quot;: [ &quot;cadvisor-exporter&quot; ], &quot;Address&quot;: &quot;192.168.31.138&quot;, &quot;Port&quot;: 18104, &quot;Meta&quot;: &#123; &quot;app&quot;: &quot;docker&quot;, &quot;team&quot;: &quot;cloudgroup&quot;, &quot;project&quot;: &quot;docker-service&quot; &#125;, &quot;EnableTagOverride&quot;: false, &quot;Check&quot;: &#123; &quot;HTTP&quot;: &quot;http://192.168.31.138:18104/metrics&quot;, &quot;Interval&quot;: &quot;1s&quot; &#125;, &quot;Weights&quot;: &#123; &quot;Passing&quot;: 10, &quot;Warning&quot;: 1 &#125;&#125; 123456789101112131415161718192021222324[root@prometheus consul]# cat windows-example.json&#123; &quot;ID&quot;: &quot;windows-exporter-192.168.31.138&quot;, &quot;Name&quot;: &quot;windows-exporter-192.168.31.138&quot;, &quot;Tags&quot;: [ &quot;windows-exporter&quot; ], &quot;Address&quot;: &quot;192.168.31.138&quot;, &quot;Port&quot;: 9100, &quot;Meta&quot;: &#123; &quot;app&quot;: &quot;windows&quot;, &quot;team&quot;: &quot;cloudgroup&quot;, &quot;project&quot;: &quot;windows-service&quot; &#125;, &quot;EnableTagOverride&quot;: false, &quot;Check&quot;: &#123; &quot;HTTP&quot;: &quot;http://192.168.31.138:9100/metrics&quot;, &quot;Interval&quot;: &quot;5s&quot; &#125;, &quot;Weights&quot;: &#123; &quot;Passing&quot;: 10, &quot;Warning&quot;: 1 &#125;&#125; 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104#!/bin/bashconsul_ip=192.168.31.132function quit_and_checkip()&#123; VALID_CHECK=$( echo $1| awk -F &quot;.&quot; &#x27;$1&lt;=255&amp;&amp;$2&lt;=255&amp;&amp;$3&lt;=255&amp;&amp;$4&lt;=255&#123;print &quot;yes&quot;&#125;&#x27; ) if [[ $1 = &quot;q&quot; || $1 = &quot;quit&quot; ]];then exit elif ! echo $1| grep -E &quot;^[0-9]&#123;1,3&#125;\\.[0-9]&#123;1,3&#125;\\.[0-9]&#123;1,3&#125;\\.[0-9]&#123;1,3&#125;$&quot; &gt; /dev/null ;then echo &quot;IP $1 格式有问题!&quot; exit elif [ ! $&#123;VALID_CHECK:-no&#125; == &quot;yes&quot; ];then echo &quot;IP $1 有问题!&quot; exit fi&#125;#cd /prometheus/consul_register/read -n 1 -p &quot;你需要注册还是删除节点,1代表增加,2代表删除:&quot; service_numif [ $service_num -eq 1 ];then echo &quot;&quot; read -n 1 -p &quot;请输入你添加的节点类型编号,1-docker,2-linux,3-windows:&quot; service_type echo &quot;&quot; case $service_type in &quot;1&quot;) while true do read -p &quot;输入注册节点的IP,输入q或quit退出:&quot; service_ip quit_and_checkip $service_ip cp docker-example.json cadvisor-exporter-$service_ip.json sed -i &quot;s/192.168.31.138/$service_ip/g&quot; cadvisor-exporter-$service_ip.json curl --request PUT --data @cadvisor-exporter-$service_ip.json http://$consul_ip:8500/v1/agent/service/register?replace-existing-checks=1 echo &quot;节点cadvisor-exporter-$service_ip注册成功&quot; done ;; &quot;2&quot;) while true do read -p &quot;输入注册节点的IP,输入q或quit退出:&quot; service_ip quit_and_checkip $service_ip cp node.json node-exporter-$service_ip.json sed -i &quot;s/192.168.31.132/$service_ip/g&quot; node-exporter-$service_ip.json curl --request PUT --data @node-exporter-$service_ip.json http://$consul_ip:8500/v1/agent/service/register?replace-existing-checks=1 echo &quot;节点node-exporter-$service_ip注册成功&quot; done ;; &quot;3&quot;) while true do read -p &quot;输入注册节点的IP,输入q或quit退出:&quot; service_ip quit_and_checkip $service_ip cp windows-example.json windows-exporter-$service_ip.json sed -i &quot;s/192.168.31.138/$service_ip/g&quot; windows-exporter-$service_ip.json curl --request PUT --data @windows-exporter-$service_ip.json http://$consul_ip:8500/v1/agent/service/register?replace-existing-checks=1 echo &quot;节点windows-exporter-$service_ip注册成功&quot; done ;; *) echo &quot;输入编号类型错误&quot; ;; esacelif [ $service_num -eq 2 ];then echo &quot;&quot; read -n 1 -p &quot;请输入你删除的节点类型编号,1-docker,2-linux,3-windows:&quot; service_type echo &quot;&quot; case $service_type in &quot;1&quot;) while true do read -p &quot;输入需要删除节点的IP,输入q或quit退出:&quot; service_ip quit_and_checkip $service_ip curl -X PUT http://$consul_ip:8500/v1/agent/service/deregister/cadvisor-exporter-$service_ip rm -rf cadvisor-exporter-$service_ip.json echo &quot;节点cadvisor-exporter-$service_ip已删除&quot; done ;; &quot;2&quot;) while true do read -p &quot;输入需要删除节点的IP,输入q或quit退出:&quot; service_ip quit_and_checkip $service_ip curl -X PUT http://$consul_ip:8500/v1/agent/service/deregister/node-exporter-$service_ip rm -rf node-exporter-$service_ip.json echo &quot;节点node-exporter-$service_ip已删除&quot; done ;; &quot;3&quot;) while true do read -p &quot;输入需要删除节点的IP,输入q或quit退出:&quot; service_ip quit_and_checkip $service_ip curl -X PUT http://$consul_ip:8500/v1/agent/service/deregister/windows-exporter-$service_ip rm -rf windows-exporter-$service_ip.json echo &quot;节点windows-exporter-$service_ip已删除&quot; done ;; *) echo &quot;输入类型错误&quot; ;; esacfi","categories":[{"name":"学习","slug":"学习","permalink":"https://carlsack.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"prometheus","slug":"prometheus","permalink":"https://carlsack.github.io/tags/prometheus/"},{"name":"监控","slug":"监控","permalink":"https://carlsack.github.io/tags/%E7%9B%91%E6%8E%A7/"},{"name":"运维","slug":"运维","permalink":"https://carlsack.github.io/tags/%E8%BF%90%E7%BB%B4/"}],"author":"CarlSack"}],"categories":[{"name":"学习","slug":"学习","permalink":"https://carlsack.github.io/categories/%E5%AD%A6%E4%B9%A0/"}],"tags":[{"name":"运维","slug":"运维","permalink":"https://carlsack.github.io/tags/%E8%BF%90%E7%BB%B4/"},{"name":"代码","slug":"代码","permalink":"https://carlsack.github.io/tags/%E4%BB%A3%E7%A0%81/"},{"name":"代理","slug":"代理","permalink":"https://carlsack.github.io/tags/%E4%BB%A3%E7%90%86/"},{"name":"prometheus","slug":"prometheus","permalink":"https://carlsack.github.io/tags/prometheus/"},{"name":"监控","slug":"监控","permalink":"https://carlsack.github.io/tags/%E7%9B%91%E6%8E%A7/"}]}